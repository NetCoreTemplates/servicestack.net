---
title: Introducing AI Server
summary: Razor SSG now includes support for Podcasts
tags: [ai-server,ai,gpt,service-reference,c#,js]
author: Demis Bellot
image: https://images.unsplash.com/photo-1642516303080-431f6681f864?crop=entropy&fit=crop&h=1000&w=2000
---

## AI Server now ready to serve!

We're excited to announce the first release of AI Server - a Free OSS self-hosted Docker private gateway to 
manage API access to multiple LLM APIs, Ollama endpoints, Media APIs, Comfy UI and FFmpeg Agents.

:::youtube Ojo80oFQte8
Introducing AI Server
:::

### Centralized Management

Designed as a one-stop solution to manage an organization's AI integrations for all their System Apps,
by utilizing developer friendly HTTP JSON APIs that supports any programming language or framework.

[![](https://openai.servicestack.net/img/overview.svg)](https://openai.servicestack.net)

### Distribute load across multiple Ollama, Open AI Gateway and Comfy UI Agents

It works as a private gateway to process LLM, AI and image transformations requests
that any of our Apps need where it dynamically load balances requests across our local GPU Servers, Cloud GPU instances
and API Gateways running multiple instances of Ollama, Open AI Chat, LLM Gateway, Comfy UI, Whisper
and ffmpeg providers.

In addition to maintaining a history of AI Requests, it also provides file storage
for its CDN-hostable AI generated assets and on-the-fly, cacheable image transformations.

### Native Typed Integrations

Uses [Add ServiceStack Reference](https://docs.servicestack.net/add-servicestack-reference) to enable
simple, native typed integrations for most popular Web, Mobile and Desktop languages including: 
C#, TypeScript, JavaScript, Python, Java, Kotlin, Dart, PHP, Swift, F# and VB.NET.

Each AI Feature supports multiple call styles for optimal integration of different usages:

- **Synchronous API** · Simplest API ideal for small workloads where the Response is returned in the same Request
- **Queued API** · Returns a reference to the queued job executing the AI Request which can be used to poll for the API Response
- **Reply to Web Callback** · Ideal for reliable App integrations where responses are posted back to a custom URL Endpoin

### Live Monitoring and Analytics

Monitor performance and statistics of all your App's AI Usage, real-time logging of executing APIs with auto archival 
of completed AI Requests into monthly rolling SQLite databases.

### Protected Access with API Keys

AI Server utilizes [Simple Auth with API Keys](https://docs.servicestack.net/auth/admin-apikeys)
letting Admins create and distribute API Keys to only allow authorized clients to access their
AI Server's APIs, which can be optionally further restricted to only
[allow access to specific APIs](https://docs.servicestack.net/auth/apikeys#creating-user-api-keys).

## Install

AI Server can be installed on macOS and Linux with Docker by running [install.sh](https://github.com/ServiceStack/ai-server/blob/main/install.sh):

### 1. Clone the Repository

Clone the AI Server repository from GitHub:

:::sh
git clone https://github.com/ServiceStack/ai-server
:::

### 2. Run the Installer

:::sh
cd ai-server && cat install.sh | bash
:::

The installer will detect common environment variables for the supported AI Providers like OpenAI, Google, Anthropic, 
and others, and prompt ask you if you want to add them to your AI Server configuration.

<div data-asciicinema="https://docs.servicestack.net/pages/ai-server/ai-server-install.cast" 
     data-options="{loop:true,poster:'npt:00:21',theme:'dracula',rows:13}"></div>

### Optional - Install ComfyUI Agent

If your server also has a GPU you can ask the installer to also install the [ComfyUI Agent](/ai-server/comfy-extension):

<div data-asciicinema="https://docs.servicestack.net/pages/ai-server/agent-comfy-install.cast" 
     data-options="{loop:true,poster:'npt:00:09',theme:'dracula',rows:16}"></div>

The ComfyUI Agent is a separate Docker agent for running [ComfyUI](https://www.comfy.org), 
[Whisper](https://github.com/openai/whisper) and [FFmpeg](https://www.ffmpeg.org) on servers with GPUs to handle 
AI Server's [Image](https://docs.servicestack.net/ai-server/transform/image) and 
[Video transformations](https://docs.servicestack.net/ai-server/transform/video) and Media Requests, including:

- [Text to Image](https://docs.servicestack.net/ai-server/text-to-image)
- [Image to Text](https://docs.servicestack.net/ai-server/image-to-text)
- [Image to Image](https://docs.servicestack.net/ai-server/image-to-image)
- [Image with Mask](https://docs.servicestack.net/ai-server/image-with-mask)
- [Image Upscale](https://docs.servicestack.net/ai-server/image-upscale)
- [Speech to Text](https://docs.servicestack.net/ai-server/speech-to-text)
- [Text to Speech](https://docs.servicestack.net/ai-server/text-to-speech)

#### Comfy UI Agent Installer

To install the ComfyUI Agent on a separate server (with a GPU), you can clone and run the ComfyUI Agent installer 
on that server instead:

```sh
git clone https://github.com/ServiceStack/agent-comfy.git
cd agent-comfy
cat install.sh | bash
```

## Running in Production

We've been developing and running AI Server for several months now, processing millions of LLM and Comfy UI Requests
to generate Open AI Chat Answers and Generated Images used to populate the
[pvq.app](https://pvq.app) and [blazordiffusion.com](https://blazordiffusion.com) websites.

Our production instance with more info about AI Server is available at:

:::{.m-0 .text-center .text-2xl .font-semibold .text-indigo-600}
https://openai.servicestack.net
:::

[![](/img/posts/ai-server/ai-server-languages.png)](https://openai.servicestack.net)

## API Explorer

Whilst our production instance is protected by API Keys, you can still use it to explore available APIs in its API Explorer:

:::{.m-0 .text-center .text-2xl .font-semibold .text-indigo-600}
[https://openai.servicestack.net/ui/](https://openai.servicestack.net/ui/OpenAiChatCompletion)
:::

## Documentation

The documentation for AI Server is being maintained at:

:::{.m-0 .text-center .text-2xl .font-semibold .text-indigo-600}
https://docs.servicestack.net/ai-server/
:::

## Built-in UIs

Built-in UIs allow users with API Keys access to custom UIs for different AI features

[![](/img/posts/ai-server/ai-server-builtin-uis.png)](https://openai.servicestack.net)

## Admin UIs

Use Admin UI to manage API Keys that can access AI Server APIs and Features

[![](/img/posts/ai-server/ai-server-admin-uis.png)](https://openai.servicestack.net)

## Features

The current release of AI Server supports a number of different modalities, including:

### Large Language Models
- [Open AI Chat](https://docs.servicestack.net/ai-server/chat)
    - Support for Ollama endpoints
    - Support for Open Router, Anthropic, Open AI, Mistral AI, Google and Groq API Gateways

### Comfy UI Agent / Replicate / DALL-E 3
 
- [Text to Image](https://docs.servicestack.net/ai-server/text-to-image)

### Comfy UI Agent
 
- [Image to Image](https://docs.servicestack.net/ai-server/image-to-image)
    - [Image Upscaling](https://docs.servicestack.net/ai-server/image-upscale)
    - [Image with Mask](https://docs.servicestack.net/ai-server/image-with-mask)
- [Image to Text](https://docs.servicestack.net/ai-server/image-to-text)
- [Text to Speech](https://docs.servicestack.net/ai-server/text-to-speech)
- [Speech to Text](https://docs.servicestack.net/ai-server/speech-to-text)
 
### FFmpeg

- [Image Transformations](https://docs.servicestack.net/ai-server/transform/image)
  - **Crop Image** - Crop an image to a specific size
  - **Convert Image** - Convert an image to a different format
  - **Scale Image** - Scale an image to a different resolution
  - **Watermark Image** - Add a watermark to an image

- [Video Transformations](https://docs.servicestack.net/ai-server/transform/video)
  - **Crop Video** - Crop a video to a specific size
  - **Convert Video** - Convert a video to a different format
  - **Scale Video** - Scale a video to a different resolution
  - **Watermark Video** - Add a watermark to a video
  - **Trim Video** - Trim a video to a specific length

### Managed File Storage
- Blob Storage - isolated and restricted by API Key

## Feedback

Feel free to reach us at [ServiceStack/Discuss](https://github.com/ServiceStack/Discuss/discussions)
if you have any questions about AI Server.