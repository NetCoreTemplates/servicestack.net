---
title: Introducing AI Server
summary: Introducing AI Server - an OSS Self Hosted Gateway for running LLM, Ollama, Media and Comfy UI APIs
tags: [ai-server,ai,gpt,service-reference,c#,js]
url: https://media.servicestack.com/podcasts/ai-server.mp3
media: {size:6185420,duration:1546.296000,format:mp3}
---

This episode covers AI Server - an open-source, self-hosted Docker gateway for managing API access to various 
AI services. It offers centralized management of LLMs, Ollama endpoints, media APIs, and Comfy UI, distributing 
loads across multiple servers. 

The system provides native typed integrations for numerous programming languages and supports synchronous, 
queued, and callback-based API calls. Comprehensive monitoring, analytics, and protected access with API keys 
are included, and the project includes installation instructions and documentation. 

Finally, AI Server is already being used in production environments.

### Videos

:::youtube Ojo80oFQte8
Introducing AI Server
:::

### Links

- [Blog Post](/posts/ai-server)
